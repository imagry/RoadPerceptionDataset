{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoadPercption Dataset Example\n",
    "\n",
    "Please make sure you have the data (imgs, gt folders) located in this directory to match the paths in data.csv file - link provided in the README file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, basename\n",
    "import cv2\n",
    "import torch\n",
    "import blosc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class RoadPerceptionDataset():\n",
    "    def __init__(self, pth):\n",
    "        self.gt_h = 224\n",
    "        self.gt_w = 280\n",
    "\n",
    "        self.df = pd.read_csv(pth, names=[\"img\",\"gt\"])\n",
    "\n",
    "        # layer index + BGR color values for visulization\n",
    "        self.layers_colormap = {\n",
    "                    'road'            : (0, [0,0,255]),     # red\n",
    "                    'stop_lines'      : (1, [0,255,255]),   # yellow\n",
    "                    'speed_bumps'     : (2, [255,0,255]),   # purple\n",
    "                    'dashed_line'     : (3, [255,255,0]),   # cyan\n",
    "                    'cont_line'       : (4, [255,255,255]), # white\n",
    "                    'zebra_crosswalk' : (5, [127,255,0]),   # light green\n",
    "                    'parking'         : (6, [33,140,33]),   # dark green\n",
    "                    'border_parking'  : (7, [180,180,180]), # gray\n",
    "                    'island'          : (8, [0,153,255]),   # orange\n",
    "                    'empty_crosswalk' : (9, [255,204,102])  # light blue\n",
    "        }\n",
    "\n",
    "        # order in which the layers are stacked for GT visualization, first on top\n",
    "        self.layers_vis_order = [\n",
    "                    'cont_line',\n",
    "                    'dashed_line',\n",
    "                    'speed_bumps',\n",
    "                    'stop_lines',\n",
    "                    'island',\n",
    "                    'zebra_crosswalk',\n",
    "                    'empty_crosswalk',\n",
    "                    'road',\n",
    "                    'border_parking',\n",
    "                    'parking'\n",
    "        ]\n",
    "        self.layers_vis_order = [list(self.layers_colormap.keys()).index(c) for c in self.layers_vis_order]\n",
    "\n",
    "        # BGR color values corresponding to each layer (first is background - black)\n",
    "        self.palettes = torch.cat((torch.ByteTensor([[0,0,0]]), torch.ByteTensor([v[1] for v in self.layers_colormap.values()])))\n",
    "\n",
    "        # 90-degree FOV mask for the top-down visualization\n",
    "        self.fov_mask = np.zeros((self.gt_h, self.gt_w))\n",
    "        xx, yy = np.meshgrid(np.arange(0,self.gt_w), np.arange(0,self.gt_h))\n",
    "        hh = (self.gt_h-1)/2\n",
    "        self.fov_mask[yy+xx < hh] = 1\n",
    "        self.fov_mask[yy-xx > hh] = 1\n",
    "    \n",
    "    # loads path to a binary GT file, returns it as a (224,280,11) numpy array\n",
    "    def load_gt(self, pth):\n",
    "        with open(pth, 'rb') as f:\n",
    "            gt = np.frombuffer(blosc.decompress(f.read()), dtype=np.bool_).reshape(self.gt_h,self.gt_w,-1)\n",
    "        return gt\n",
    "    \n",
    "    # gets an (h,w,c) array of layers, returns a (h,w,3) RGB visulization of it\n",
    "    def layers_to_rgb(self, layers, show_masks=True, show_car=True, alpha=60):\n",
    "        rgb = torch.zeros(layers.shape[:2], dtype=torch.long)\n",
    "        for i in self.layers_vis_order[::-1]:\n",
    "            rgb[layers[...,i]]=i+1\n",
    "        rgb = self.palettes[rgb]\n",
    "        if show_masks:\n",
    "            occ_fov_mask = np.logical_or(self.fov_mask, layers[...,-1])\n",
    "            rgb[occ_fov_mask] = (rgb[occ_fov_mask].to(torch.int32)*alpha//100 + 255*(100-alpha)//100).to(torch.uint8)\n",
    "        if show_car:\n",
    "            hh = rgb.shape[0]//2\n",
    "            rgb[hh-5:hh+6,:10] = 255\n",
    "        return rgb\n",
    "    \n",
    "    # returns a single pair of img-gt paths from the dataset, either randomly or by a specified index\n",
    "    def get_sample_paths(self, idx=None):\n",
    "        return self.df.iloc[idx if idx is not None else np.random.randint(len(self.df))]\n",
    "    \n",
    "    # gets a pair of img-gt paths, returns a side-by-side visualization of them\n",
    "    def get_sample(self, img_pth, gt_pth):\n",
    "        gt = self.load_gt(gt_pth)\n",
    "        gt_vis = self.layers_to_rgb(gt)\n",
    "        img = cv2.resize(cv2.imread(img_pth), gt_vis.shape[:2][::-1])\n",
    "        return np.concatenate((img,gt_vis), axis=1)\n",
    "    \n",
    "    # gets a pair of img-gt paths, presents their side-by-side visualization\n",
    "    def visualize_sample(self, img_pth, gt_pth):\n",
    "        img_gt_sample = self.get_sample(img_pth, gt_pth)\n",
    "        trip, img_ts, cam = gt_pth.rsplit('/',3)[1], basename(img_pth), gt_pth.rsplit('/',2)[1].split('_')[1]\n",
    "        plt.figure(figsize=(12,30))\n",
    "        plt.title(f\"trip: {trip}, img: {img_ts}, cam: {cam}\")\n",
    "        plt.imshow(img_gt_sample[...,::-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Pairs of image vs GT of binary top-down layers, which cover 75x60 meters (more details below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"data.csv\"\n",
    "\n",
    "rp_data = RoadPerceptionDataset(datafile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Samples\n",
    "\n",
    "For visualization, GT layers are stacked on top of each other with the following colors:\n",
    "\n",
    "- Road (red)\n",
    "- Stop lines (yellow)\n",
    "- Speed bumps (purple)\n",
    "- Dashed lane dividers (cyan)\n",
    "- Continuous lane dividers (white)\n",
    "- Marked crosswalks (light green)\n",
    "- Parking spaces (dark green)\n",
    "- Parking borders (gray)\n",
    "- Painted islands (orange)\n",
    "- Unmarked crosswalks (light blue)\n",
    "- Occlusion mask - buildings, walls and other static obstacles (transparent)\n",
    "\n",
    "Run this cell to visualize one sample at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pth, gt_pth = rp_data.get_sample_paths()\n",
    "\n",
    "print(f\"selected sample:\\n{img_pth}\\n{gt_pth}\\n\")\n",
    "\n",
    "if isfile(img_pth) and isfile(gt_pth):\n",
    "    rp_data.visualize_sample(img_pth, gt_pth)\n",
    "else:\n",
    "    print(\"image and/or gt file not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7efec1d1e32386799e5717d4bc20f2efaf7546b1459d5dad6c0ec2ee9543c72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
